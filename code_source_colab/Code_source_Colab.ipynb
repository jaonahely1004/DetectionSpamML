{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importer les biblioth√®ques\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# -----------------------------\n",
        "# 0Ô∏è‚É£ T√©l√©charger les stopwords fran√ßais\n",
        "# -----------------------------\n",
        "nltk.download('stopwords')\n",
        "french_stopwords = stopwords.words('french')\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ Charger le dataset multilingue (SMS Spam Multilingual) et filtrer le fran√ßais\n",
        "# -----------------------------\n",
        "dataset = load_dataset(\"dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset\")\n",
        "\n",
        "# R√©cup√©rer uniquement les messages fran√ßais\n",
        "texts_fr = [x[\"text_fr\"] for x in dataset[\"train\"]]  # colonne pour fran√ßais\n",
        "labels = [1 if x[\"labels\"] == \"spam\" else 0 for x in dataset[\"train\"]]  # colonne \"labels\"\n",
        "\n",
        "print(\"Nombre de messages :\", len(texts_fr))\n",
        "print(\"Labels disponibles :\", set(labels))\n",
        "print(\"Exemple message :\", texts_fr[0], \"| Label :\", labels[0])\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Split train/test\n",
        "# -----------------------------\n",
        "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
        "    texts_fr, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ TF-IDF (avec stopwords fran√ßais)\n",
        "# -----------------------------\n",
        "vectorizer = TfidfVectorizer(stop_words=french_stopwords, max_df=0.9, max_features=2000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_texts)\n",
        "X_test_tfidf = vectorizer.transform(X_test_texts)\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Features manuelles suppl√©mentaires\n",
        "# -----------------------------\n",
        "def add_manual_features(texts):\n",
        "    \"\"\"\n",
        "    Features simples pour le spam :\n",
        "    - nb de chiffres\n",
        "    - nb de symboles sp√©ciaux !,$,‚Ç¨\n",
        "    - longueur du message\n",
        "    \"\"\"\n",
        "    digits = [sum(c.isdigit() for c in t) for t in texts]\n",
        "    symbols = [sum(c in \"!$‚Ç¨\" for c in t) for t in texts]\n",
        "    length = [len(t) for t in texts]\n",
        "    return np.array([digits, symbols, length]).T\n",
        "\n",
        "X_train_manual = csr_matrix(add_manual_features(X_train_texts))\n",
        "X_test_manual = csr_matrix(add_manual_features(X_test_texts))\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Combiner TF-IDF + features manuelles\n",
        "# -----------------------------\n",
        "X_train_final = hstack([X_train_tfidf, X_train_manual])\n",
        "X_test_final = hstack([X_test_tfidf, X_test_manual])\n",
        "\n",
        "print(\"Donn√©es combin√©es TF-IDF + features manuelles ‚úÖ\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ Entra√Æner Random Forest\n",
        "# -----------------------------\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf_model.fit(X_train_final, y_train)\n",
        "print(\"Mod√®le Random Forest entra√Æn√© ‚úÖ\")\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ √âvaluer le mod√®le\n",
        "# -----------------------------\n",
        "preds = rf_model.predict(X_test_final)\n",
        "print(\"Accuracy :\", accuracy_score(y_test, preds))\n",
        "print(\"\\nClassification Report :\\n\", classification_report(y_test, preds, target_names=[\"HAM\", \"SPAM\"]))\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ Sauvegarder le mod√®le et le vectorizer\n",
        "# -----------------------------\n",
        "joblib.dump(rf_model, \"spam_rf_model_fr.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer_fr.pkl\")\n",
        "print(\"Mod√®le et vectorizer sauvegard√©s ‚úÖ\")\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ Fonction pour pr√©dire un nouveau message\n",
        "# -----------------------------\n",
        "def predict_message(message):\n",
        "    tfidf_vec = vectorizer.transform([message])\n",
        "    manual_vec = csr_matrix(add_manual_features([message]))\n",
        "    combined_vec = hstack([tfidf_vec, manual_vec])\n",
        "    pred = rf_model.predict(combined_vec)[0]\n",
        "    conf = rf_model.predict_proba(combined_vec)[0][pred] * 100\n",
        "    return {\"prediction\": \"SPAM\" if pred==1 else \"HAM\", \"confidence\": round(conf,2)}\n",
        "\n",
        "# -----------------------------\n",
        "# üîü Tests\n",
        "# -----------------------------\n",
        "message_test_spam = \"Je n'y connaissais rien en informatique ou en finance. En suivant simplement les instructions pendant 10 minutes par jour, j'ai g√©n√©r√© 4 500 ‚Ç¨ d√®s la premi√®re semaine. Ma vie a totalement chang√©, merci !\"\n",
        "message_test_ham = \"Salut, on se retrouve demain pour le cours de maths ?\"\n",
        "\n",
        "result_spam = predict_message(message_test_spam)\n",
        "result_ham = predict_message(message_test_ham)\n",
        "\n",
        "print(\"\\nTest SPAM :\", message_test_spam)\n",
        "print(\"Pr√©diction :\", result_spam[\"prediction\"], \"| Confiance :\", result_spam[\"confidence\"], \"%\")\n",
        "\n",
        "print(\"\\nTest HAM :\", message_test_ham)\n",
        "print(\"Pr√©diction :\", result_ham[\"prediction\"], \"| Confiance :\", result_ham[\"confidence\"], \"%\")\n"
      ],
      "metadata": {
        "id": "GfFdlkQU2QNw",
        "outputId": "dd19be9d-b22f-4399-b648-3fbb732b77d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de messages : 5572\n",
            "Labels disponibles : {0, 1}\n",
            "Exemple message : Allez jusqu'√† Jurong point, fou.. Disponible seulement dans bugis n grand monde la e buffet... Cine il y a eu plus... | Label : 0\n",
            "Donn√©es combin√©es TF-IDF + features manuelles ‚úÖ\n",
            "Mod√®le Random Forest entra√Æn√© ‚úÖ\n",
            "Accuracy : 0.9883408071748879\n",
            "\n",
            "Classification Report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         HAM       0.99      1.00      0.99       966\n",
            "        SPAM       1.00      0.91      0.95       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.99      0.96      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n",
            "Mod√®le et vectorizer sauvegard√©s ‚úÖ\n",
            "\n",
            "Test SPAM : Je n'y connaissais rien en informatique ou en finance. En suivant simplement les instructions pendant 10 minutes par jour, j'ai g√©n√©r√© 4 500 ‚Ç¨ d√®s la premi√®re semaine. Ma vie a totalement chang√©, merci !\n",
            "Pr√©diction : SPAM | Confiance : 67.67 %\n",
            "\n",
            "Test HAM : Salut, on se retrouve demain pour le cours de maths ?\n",
            "Pr√©diction : HAM | Confiance : 99.0 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}